# coding=utf-8
# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for license information.
# Code generated by Microsoft (R) Python Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------

from enum import Enum
from azure.core import CaseInsensitiveEnumMeta


class AudioTaskLabel(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Defines the possible descriptors for available audio operation responses."""

    TRANSCRIBE = "transcribe"
    """Accompanying response data resulted from an audio transcription task."""
    TRANSLATE = "translate"
    """Accompanying response data resulted from an audio translation task."""


class AudioTranscriptionFormat(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Defines available options for the underlying response format of output transcription
    information.
    """

    JSON = "json"
    """Use a response body that is a JSON object containing a single 'text' field for the
    transcription."""
    VERBOSE_JSON = "verbose_json"
    """Use a response body that is a JSON object containing transcription text along with timing,
    segments, and other
    metadata."""
    TEXT = "text"
    """Use a response body that is plain text containing the raw, unannotated transcription."""
    SRT = "srt"
    """Use a response body that is plain text in SubRip (SRT) format that also includes timing
    information."""
    VTT = "vtt"
    """Use a response body that is plain text in Web Video Text Tracks (VTT) format that also includes
    timing information."""


class AudioTranscriptionTimestampGranularity(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Defines the timestamp granularities that can be requested on a verbose transcription response."""

    WORD = "word"
    """Indicates that responses should include timing information about each transcribed word. Note
    that generating word
    timestamp information will incur additional response latency."""
    SEGMENT = "segment"
    """Indicates that responses should include timing and other information about each transcribed
    audio segment. Audio
    segment timestamp information does not incur any additional latency."""


class AudioTranslationFormat(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Defines available options for the underlying response format of output translation information."""

    JSON = "json"
    """Use a response body that is a JSON object containing a single 'text' field for the translation."""
    VERBOSE_JSON = "verbose_json"
    """Use a response body that is a JSON object containing translation text along with timing,
    segments, and other
    metadata."""
    TEXT = "text"
    """Use a response body that is plain text containing the raw, unannotated translation."""
    SRT = "srt"
    """Use a response body that is plain text in SubRip (SRT) format that also includes timing
    information."""
    VTT = "vtt"
    """Use a response body that is plain text in Web Video Text Tracks (VTT) format that also includes
    timing information."""


class AzureChatExtensionRetrieveDocumentFilterReason(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The reason for filtering the retrieved document."""

    SCORE = "score"
    """The document is filtered by original search score threshold defined by ``strictness``
    configure."""
    RERANK = "rerank"
    """The document is not filtered by original search score threshold, but is filtered by rerank
    score and ``top_n_documents`` configure."""


class AzureChatExtensionType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """A representation of configuration data for a single Azure OpenAI chat extension. This will be
    used by a chat
      completions request that should use Azure OpenAI chat extensions to augment the response
    behavior.
      The use of this configuration is compatible only with Azure OpenAI.
    """

    AZURE_SEARCH = "azure_search"
    """Represents the use of Azure AI Search as an Azure OpenAI chat extension."""
    AZURE_COSMOS_DB = "azure_cosmos_db"
    """Represents the use of Azure Cosmos DB as an Azure OpenAI chat extension."""
    ELASTICSEARCH = "elasticsearch"
    """Represents the use of ElasticsearchÂ® index as an Azure OpenAI chat extension."""
    PINECONE = "pinecone"
    """Represents the use of Pinecone index as an Azure OpenAI chat extension."""
    MONGO_DB = "mongo_db"
    """Represents the use of a MongoDB chat extension."""


class AzureSearchQueryType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The type of Azure Search retrieval query that should be executed when using it as an Azure
    OpenAI chat extension.
    """

    SIMPLE = "simple"
    """Represents the default, simple query parser."""
    SEMANTIC = "semantic"
    """Represents the semantic query parser for advanced semantic modeling."""
    VECTOR = "vector"
    """Represents vector search over computed data."""
    VECTOR_SIMPLE_HYBRID = "vector_simple_hybrid"
    """Represents a combination of the simple query strategy with vector data."""
    VECTOR_SEMANTIC_HYBRID = "vector_semantic_hybrid"
    """Represents a combination of semantic search and vector data querying."""


class BatchStatus(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The status of a batch."""

    VALIDATING = "validating"
    """The input file is being validated before the batch can begin."""
    FAILED = "failed"
    """The input file has failed the validation process."""
    IN_PROGRESS = "in_progress"
    """The input file was successfully validated and the batch is currently being executed."""
    FINALIZING = "finalizing"
    """The batch has completed and the results are being prepared."""
    COMPLETED = "completed"
    """The batch has been completed and the results are ready."""
    EXPIRED = "expired"
    """The batch was not able to complete within the 24-hour time window."""
    CANCELLING = "cancelling"
    """Cancellation of the batch has been initiated."""
    CANCELLED = "cancelled"
    """The batch was cancelled."""


class ChatCompletionsToolSelectionPreset(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Represents a generic policy for how a chat completions tool may be selected."""

    AUTO = "auto"
    """Specifies that the model may either use any of the tools provided in this chat completions
    request or
    instead return a standard chat completions response as if no tools were provided."""
    NONE = "none"
    """Specifies that the model should not respond with a tool call and should instead provide a
    standard chat
    completions response. Response content may still be influenced by the provided tool
    definitions."""
    REQUIRED = "required"
    """Specifies that the model must call one or more tools."""


class ChatMessageImageDetailLevel(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """A representation of the possible image detail levels for image-based chat completions message
    content.
    """

    AUTO = "auto"
    """Specifies that the model should determine which detail level to apply using heuristics like
    image size."""
    LOW = "low"
    """Specifies that image evaluation should be constrained to the 'low-res' model that may be faster
    and consume fewer
    tokens but may also be less accurate for highly detailed images."""
    HIGH = "high"
    """Specifies that image evaluation should enable the 'high-res' model that may be more accurate
    for highly detailed
    images but may also be slower and consume more tokens."""


class ChatRole(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """A description of the intended purpose of a message within a chat completions interaction."""

    SYSTEM = "system"
    """The role that instructs or sets the behavior of the assistant."""
    ASSISTANT = "assistant"
    """The role that provides responses to system-instructed, user-prompted input."""
    USER = "user"
    """The role that provides input for chat completions."""
    FUNCTION = "function"
    """The role that provides function results for chat completions."""
    TOOL = "tool"
    """The role that represents extension tool activity within a chat completions operation."""


class CompletionsFinishReason(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Representation of the manner in which a completions response concluded."""

    STOPPED = "stop"
    """Completions ended normally and reached its end of token generation."""
    TOKEN_LIMIT_REACHED = "length"
    """Completions exhausted available token limits before generation could complete."""
    CONTENT_FILTERED = "content_filter"
    """Completions generated a response that was identified as potentially sensitive per content
    moderation policies."""
    FUNCTION_CALL = "function_call"
    """Completion ended normally, with the model requesting a function to be called."""
    TOOL_CALLS = "tool_calls"
    """Completion ended with the model calling a provided tool for output."""


class ContentFilterSeverity(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Ratings for the intensity and risk level of harmful content."""

    SAFE = "safe"
    """Content may be related to violence, self-harm, sexual, or hate categories but the terms
    are used in general, journalistic, scientific, medical, and similar professional contexts,
    which are appropriate for most audiences."""
    LOW = "low"
    """Content that expresses prejudiced, judgmental, or opinionated views, includes offensive
    use of language, stereotyping, use cases exploring a fictional world (for example, gaming,
    literature) and depictions at low intensity."""
    MEDIUM = "medium"
    """Content that uses offensive, insulting, mocking, intimidating, or demeaning language
    towards specific identity groups, includes depictions of seeking and executing harmful
    instructions, fantasies, glorification, promotion of harm at medium intensity."""
    HIGH = "high"
    """Content that displays explicit and severe harmful instructions, actions,
    damage, or abuse; includes endorsement, glorification, or promotion of severe
    harmful acts, extreme or illegal forms of harm, radicalization, or non-consensual
    power exchange or abuse."""


class ElasticsearchQueryType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The type of ElasticsearchÂ® retrieval query that should be executed when using it as an Azure
    OpenAI chat extension.
    """

    SIMPLE = "simple"
    """Represents the default, simple query parser."""
    VECTOR = "vector"
    """Represents vector search over computed data."""


class EmbeddingEncodingFormat(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Represents the available formats for embeddings data on responses."""

    FLOAT = "float"
    """Specifies that responses should provide arrays of floats for each embedding."""
    BASE64 = "base64"
    """Specifies that responses should provide a base64-encoded string for each embedding."""


class FilePurpose(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The possible values denoting the intended usage of a file."""

    FINE_TUNE = "fine-tune"
    """Indicates a file is used for fine tuning input."""
    FINE_TUNE_RESULTS = "fine-tune-results"
    """Indicates a file is used for fine tuning results."""
    ASSISTANTS = "assistants"
    """Indicates a file is used as input to assistants."""
    ASSISTANTS_OUTPUT = "assistants_output"
    """Indicates a file is used as output by assistants."""
    BATCH = "batch"
    """Indicates a file is used as input to ."""
    BATCH_OUTPUT = "batch_output"
    """Indicates a file is used as output by a vector store batch operation."""
    VISION = "vision"
    """Indicates a file is used as input to a vision operation."""


class FileState(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The state of the file."""

    UPLOADED = "uploaded"
    """The file has been uploaded but it's not yet processed. This state is not returned by Azure
    OpenAI and exposed only for
    compatibility. It can be categorized as an inactive state."""
    PENDING = "pending"
    """The operation was created and is not queued to be processed in the future. It can be
    categorized as an inactive state."""
    RUNNING = "running"
    """The operation has started to be processed. It can be categorized as an active state."""
    PROCESSED = "processed"
    """The operation has successfully processed and is ready for consumption. It can be categorized as
    a terminal state."""
    ERROR = "error"
    """The operation has completed processing with a failure and cannot be further consumed. It can be
    categorized as a terminal state."""
    DELETING = "deleting"
    """The entity is in the process to be deleted. This state is not returned by Azure OpenAI and
    exposed only for compatibility.
    It can be categorized as an active state."""
    DELETED = "deleted"
    """The entity has been deleted but may still be referenced by other entities predating the
    deletion. It can be categorized as a
    terminal state."""


class FunctionCallPreset(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The collection of predefined behaviors for handling request-provided function information in a
    chat completions
    operation.
    """

    AUTO = "auto"
    """Specifies that the model may either use any of the functions provided in this chat completions
    request or
    instead return a standard chat completions response as if no functions were provided."""
    NONE = "none"
    """Specifies that the model should not respond with a function call and should instead provide a
    standard chat
    completions response. Response content may still be influenced by the provided function
    information."""


class ImageGenerationQuality(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """An image generation configuration that specifies how the model should prioritize quality, cost,
    and speed.
    Only configurable with dall-e-3 models.
    """

    STANDARD = "standard"
    """Requests image generation with standard, balanced characteristics of quality, cost, and speed."""
    HD = "hd"
    """Requests image generation with higher quality, higher cost and lower speed relative to
    standard."""


class ImageGenerationResponseFormat(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The format in which the generated images are returned."""

    URL = "url"
    """Image generation response items should provide a URL from which the image may be retrieved."""
    BASE64 = "b64_json"
    """Image generation response items should provide image data as a base64-encoded string."""


class ImageGenerationStyle(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """An image generation configuration that specifies how the model should incorporate realism and
    other visual characteristics.
    Only configurable with dall-e-3 models.
    """

    NATURAL = "natural"
    """Requests image generation in a natural style with less preference for dramatic and
    hyper-realistic characteristics."""
    VIVID = "vivid"
    """Requests image generation in a vivid style with a higher preference for dramatic and
    hyper-realistic
    characteristics."""


class ImageSize(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The desired size of generated images."""

    SIZE256_X256 = "256x256"
    """Very small image size of 256x256 pixels.
    Only supported with dall-e-2 models."""
    SIZE512_X512 = "512x512"
    """A smaller image size of 512x512 pixels.
    Only supported with dall-e-2 models."""
    SIZE1024_X1024 = "1024x1024"
    """A standard, square image size of 1024x1024 pixels.
    Supported by both dall-e-2 and dall-e-3 models."""
    SIZE1792_X1024 = "1792x1024"
    """A wider image size of 1024x1792 pixels.
    Only supported with dall-e-3 models."""
    SIZE1024_X1792 = "1024x1792"
    """A taller image size of 1792x1024 pixels.
    Only supported with dall-e-3 models."""


class OnYourDataAuthenticationType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The authentication types supported with Azure OpenAI On Your Data."""

    API_KEY = "api_key"
    """Authentication via API key."""
    CONNECTION_STRING = "connection_string"
    """Authentication via connection string."""
    KEY_AND_KEY_ID = "key_and_key_id"
    """Authentication via key and key ID pair."""
    ENCODED_API_KEY = "encoded_api_key"
    """Authentication via encoded API key."""
    ACCESS_TOKEN = "access_token"
    """Authentication via access token."""
    SYSTEM_ASSIGNED_MANAGED_IDENTITY = "system_assigned_managed_identity"
    """Authentication via system-assigned managed identity."""
    USER_ASSIGNED_MANAGED_IDENTITY = "user_assigned_managed_identity"
    """Authentication via user-assigned managed identity."""
    USERNAME_AND_PASSWORD = "username_and_password"
    """Authentication via username and password."""


class OnYourDataContextProperty(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The context property."""

    CITATIONS = "citations"
    """The ``citations`` property."""
    INTENT = "intent"
    """The ``intent`` property."""
    ALL_RETRIEVED_DOCUMENTS = "all_retrieved_documents"
    """The ``all_retrieved_documents`` property."""


class OnYourDataVectorizationSourceType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Represents the available sources Azure OpenAI On Your Data can use to configure vectorization
    of data for use with
    vector search.
    """

    ENDPOINT = "endpoint"
    """Represents vectorization performed by public service calls to an Azure OpenAI embedding model."""
    DEPLOYMENT_NAME = "deployment_name"
    """Represents an Ada model deployment name to use. This model deployment must be in the same Azure
    OpenAI resource, but
    On Your Data will use this model deployment via an internal call rather than a public one,
    which enables vector
    search even in private networks."""
    MODEL_ID = "model_id"
    """Represents a specific embedding model ID as defined in the search service.
    Currently only supported by ElasticsearchÂ®."""
    INTEGRATED = "integrated"
    """Represents the integrated vectorizer defined within the search resource."""


class OnYourDataVectorSearchAuthenticationType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The authentication types supported with Azure OpenAI On Your Data vector search."""

    API_KEY = "api_key"
    """Authentication via API key."""
    ACCESS_TOKEN = "access_token"
    """Authentication via access token."""


class SpeechGenerationResponseFormat(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The supported audio output formats for text-to-speech."""

    MP3 = "mp3"
    """Use MP3 as the audio output format. MP3 is the default, general-purpose format."""
    OPUS = "opus"
    """Use Opus as the audio output format. Opus is optimized for internet streaming and low latency."""
    AAC = "aac"
    """Use AAC as the audio output format. AAC is optimized for digital audio compression and is
    preferred by YouTube, Android, and iOS."""
    FLAC = "flac"
    """Use FLAC as the audio output format. FLAC is a fully lossless format optimized for maximum
    quality at the expense of size."""
    WAV = "wav"
    """Use uncompressed WAV as the audio output format, suitable for low-latency applications to avoid
    decoding overhead."""
    PCM = "pcm"
    """Use uncompressed PCM as the audio output format, which is similar to WAV but contains raw
    samples in 24kHz (16-bit signed, low-endian), without the header."""


class SpeechVoice(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The available voices for text-to-speech."""

    ALLOY = "alloy"
    """The Alloy voice."""
    ECHO = "echo"
    """The Echo voice."""
    FABLE = "fable"
    """The Fable voice."""
    ONYX = "onyx"
    """The Onyx voice."""
    NOVA = "nova"
    """The Nova voice."""
    SHIMMER = "shimmer"
    """The Shimmer voice."""
